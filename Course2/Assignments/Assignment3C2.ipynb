{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f55ed771-87cd-4e6a-b2e5-dabb40cd3314",
   "metadata": {},
   "source": [
    "# **Assignment 3**\n",
    "**Data Science Tools and Advanced Modelling Techniques**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d990005f-ce6d-4f7a-833d-b24cda73ff07",
   "metadata": {},
   "source": [
    "## Student Information\n",
    "\n",
    "**Your name (as appears on Canvas):**\n",
    "\n",
    "**Your student ID:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6b6590-dfe3-4d53-90f1-0dd6605594b6",
   "metadata": {},
   "source": [
    "## Marks\n",
    "\n",
    "**Total Marks earned:** \n",
    "\n",
    "**Score for Full Marks:**  70\n",
    "\n",
    "**Bonus marks:** 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f91420-ce72-4ac2-a88f-1e68366639f5",
   "metadata": {},
   "source": [
    "## Assignment Outline\n",
    "\n",
    "Throughout this course's assignment series, you will get the training needed to complete the final report. With each new assignment in this course, you will master the technical skills to implement analyses (Assignment 1), train reproducible research practices (Assignment 2), and learn key concepts regarding prediction modelling (Assignment 3).\n",
    "\n",
    "In Assignment 3, you will learn more about key concepts of prediction modelling:\n",
    "\n",
    "- Implementation of Basic Supervised Learning Methods (KNN and Linear Regression)\n",
    "\n",
    "- Prediction Error Sources (Underfitting vs. Overfitting)\n",
    "\n",
    "- Prediction Performance Measures\n",
    "\n",
    "- Predictive Performance Assessment Methods (Hold-Out Set)\n",
    "\n",
    "- Variable Selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e06b753-52a7-4a1d-86e1-94db0363e644",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The goal of prediction modelling is to predict an outcome variable using other available variables (i.e. predictors) for new and previously unseen subjects/units. This makes prediction modelling desirable given its applicability to many different problems (e.g., medical patient outcomes, weather, image recognition, finances, etc.), and that is why machine learning has become a very popular discipline these past few decades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2658079e-960f-4e54-b6c9-5da9e4d71968",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "**Objective**: We're going to apply linear regression modelling to the Ames City Iowa housing dataset and attempt to predict Sale Price using the following variables:\n",
    "\n",
    "- Land Slope\n",
    "- Lot Area\n",
    "- Overall Condition\n",
    "- First Floor Surface Area (Square Feet)\n",
    "- Building Type\n",
    "\n",
    "Please run this code before proceeding and examine the variables we'll be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfc92ec-841f-4a27-b463-d664b0ab2d42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(200)\n",
    "library(tidyverse)\n",
    "Ames_Data = read_csv(\"./data/ames.csv\")\n",
    "Ames_Data=Ames_Data[,c(\"Sale_Price\",\"Land_Slope\",\"Lot_Area\",\"Overall_Cond\",\"First_Flr_SF\",\"Bldg_Type\")]\n",
    "head(Ames_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8005e64-fd32-4ee8-92d0-01a1f49e0814",
   "metadata": {},
   "source": [
    "Next, we want to divide our dataset into a training set (to train the model) and a test set (to test the model's performance). Let's proceed by using 80% of the original dataset as our train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a917c0-c834-4356-9867-659af01e9e6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Train_SI = sample(1:nrow(Ames_Data), size=ceiling(0.8*nrow(Ames_Data)))\n",
    "Test_SI = which(!(1:nrow(Ames_Data) %in% Train_SI))\n",
    "Ames_Train = Ames_Data[Train_SI,]\n",
    "Ames_Test = Ames_Data[Test_SI,]\n",
    "paste(\"Number of Observations in Training Set: \", nrow(Ames_Train), sep=\"\")\n",
    "paste(\"Number of Observations in Test Set: \", nrow(Ames_Test), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebc3aef-86ac-4ab7-85fa-8869cfab7a34",
   "metadata": {},
   "source": [
    "### Part A\n",
    "\n",
    "Explain, in your own words, why have we decided to split the dataset into two parts **before** creating our prediction model?\n",
    "\n",
    "**Hint:** Think about the problem that happens if we don't split the dataset and use the entire dataset to both build and test our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5e313f-3c5a-45b1-be6e-e7636e239674",
   "metadata": {},
   "source": [
    "(5 points) for providing the appropriate reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d69e26b-6ed1-426d-b9c1-fffb0b92b322",
   "metadata": {},
   "source": [
    "**[Answer Here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb54de1-20c0-47ac-9235-4367bf56009c",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "Let's fit a linear regression to model Sale Price in terms of the other variables listed above in the objective. Complete the following code (replace the `...` with appropriate code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ac537-bd7b-4c35-9d97-fdc8c12e072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SalePrice_Model = ...(..., data=...)\n",
    "summary(SalePrice_Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0320aa-2304-403b-9d06-f1e5adc4fe5b",
   "metadata": {},
   "source": [
    "Intepreting Model Output: \n",
    "- What is the coefficient value for First Floor Surface Area?\n",
    "- Which coefficient is not statistically signficant at the 5% level?\n",
    "- What is the standard error for the coefficient corresponding to \"Poor\" Overall Condition?\n",
    "\n",
    "**Hint:** Recall that \"e+XX\" indicates how many decimal places to move the decimal to the right. So 5.000e+04 is 5000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d159a1d2-1a88-4f3c-a638-4d269ab681e4",
   "metadata": {},
   "source": [
    "(10 points) - 4 points for correct code completion, 2 points for each question answered correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5fd7da-1f81-4e64-99df-cf57da138e2f",
   "metadata": {},
   "source": [
    "**[Answer Here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5900d015-1f32-4d07-a59e-c5acf8de677e",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "Now we want to test the predictive performance of this linear regression model. What is an appropriate choice of performance measures to use here?\n",
    "\n",
    "**A)** Sensitivity\n",
    "\n",
    "**B)** Mean Squared Error\n",
    "\n",
    "**C)** Krippendorf's Alpha\n",
    "\n",
    "**D)** Area Under the Curve\n",
    "\n",
    "**E)** Matthew's Correlation Coefficient\n",
    "\n",
    "**Hint:** Think about the type of outcome we are predicting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11457ee-5e68-436b-bc2a-ae50a6f2905a",
   "metadata": {},
   "source": [
    "(5 points) for correct choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bd6a81-a278-4158-aeea-20e98ef08ee4",
   "metadata": {},
   "source": [
    "**[Answer Here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a13fa4-dcee-41a4-86e5-6785b834fd64",
   "metadata": {},
   "source": [
    "### Part D\n",
    "\n",
    "Let's choose to use mean absolute error (MAE) to assess the performance of our model. Complete the below code to compute this measure for both the training set and the test set (replace the `...` with appropriate code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dcb1ee-1666-4864-b765-026a8d64d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingSetError = sum(abs(predict(..., Ames_Train) - ...))/nrow(...)\n",
    "TestSetError = sum(abs(predict(..., Ames_Test) - ...))/nrow(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e4559-b98f-42dc-b050-0b7adfd6cc90",
   "metadata": {},
   "source": [
    "**Hint:** Recall the expression for mean absolute error (MAE). What absolute differences are we taking and summing together?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a11f837-423d-46e6-a46f-0e9779c69208",
   "metadata": {},
   "source": [
    "(5 points) for correct code completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8074642b-29cf-469b-b3af-f40ddac12810",
   "metadata": {},
   "source": [
    "### Part E\n",
    "\n",
    "In an effort to improve the linear regression model's performance, a student includes many of the other available variables as predictors in the model. The student also tries out many different combinations of those predictors and selects a final model based on the best performance on the test set. Name at least one possible problem with this modelling approach, if we assume to use the same above modelling procedure (i.e. every new model is repeatedly built using the same code as above, only the model predictors change). Please explain in a couple of sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf742b-e270-40fb-8d89-46625164a4a7",
   "metadata": {},
   "source": [
    "(5 points, 5 bonus) - For naming one problem correctly, bonus marks as well for naming two problems correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eb3162-6e66-440a-a4f5-731f72900adb",
   "metadata": {},
   "source": [
    "**[Answer Here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c98046-951b-4706-bd81-58ec100a28e8",
   "metadata": {},
   "source": [
    "### Part F\n",
    "\n",
    "Let's assume that the above student is interested in performing model selection (i.e. selecting predictors), and wants to select the final model that minimizes the performance measure they're using. How can the student update their modelling pipeline so that predictive performance of the selected final model can still be assessed accurately? \n",
    "\n",
    "Choose **all** that apply:\n",
    "\n",
    "**A)** Use a training/validation/test split of the dataset\n",
    "\n",
    "**B)** Use a bootstrap validation\n",
    "\n",
    "**C)** Use a repeated cross-validation\n",
    "\n",
    "**D)** Use a nested cross-validation\n",
    "\n",
    "**E)** Use a LOESS instead of linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a987b8c-596b-40d6-93c4-70edde75f01b",
   "metadata": {},
   "source": [
    "(5 points) for correct choices selected, -2 marks for each incorrect choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31ca8af-7aa4-4660-9bed-ebf9e34e6dbf",
   "metadata": {},
   "source": [
    "**[Answer Here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4262aa2-8080-4ab8-93f6-ed9b71e8fc2f",
   "metadata": {},
   "source": [
    "### Part G - (BONUS)\n",
    "\n",
    "To tackle the problem of model selection, the student decides to use a LASSO model instead of a linear regression. What is the problem with using a LASSO model to build a prediction model here? Assume that the correct predictive performance assessment pipeline is being used.\n",
    "\n",
    "**Hint:** Look at the variable types of the predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4462dade-c602-45ac-b0c4-67cd985cc7af",
   "metadata": {},
   "source": [
    "(5 bonus) for correct identification of problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841b0f89-b06c-4d65-9557-076b8c49e1b7",
   "metadata": {},
   "source": [
    "**[Answer Here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957267e3-8887-4276-b7ad-7dcd7046d90f",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "**Objective**: Next, we're going to now use k-nearest neighbours (k=9) to predict Central Air Conditioning (Y/N) using the following variables:\n",
    "\n",
    "- Ground Living Area (Square Feet)\n",
    "- Lot Area\n",
    "- Total Basement Surface Area (Square Feet)\n",
    "- First Floor Surface Area (Square Feet)\n",
    "- Garage Area\n",
    "\n",
    "Please run this code before proceeding and examine the variables we'll be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8e48f-ceef-41c9-ad2c-027b5a28f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(300)\n",
    "library(tidyverse)\n",
    "library(class)\n",
    "Ames_Data = read_csv(\"./data/ames.csv\")\n",
    "Ames_X_Data=as.data.frame(Ames_Data[,c(\"Gr_Liv_Area\",\"Lot_Area\",\"Total_Bsmt_SF\",\"First_Flr_SF\",\"Garage_Area\")])\n",
    "Ames_Y_Data=as.vector(data.frame(Ames_Data)[,\"Central_Air\"])\n",
    "Ames_Y_Data=factor(Ames_Y_Data, levels=c(\"Y\", \"N\"))\n",
    "head(Ames_X_Data)\n",
    "table(Ames_Y_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a86496-7065-4ab2-975b-44bf49ebb18e",
   "metadata": {},
   "source": [
    "And then again, we want to divide our dataset into a training set (to train the model) and a test set (to test the model's performance). Let's proceed by using 80% of the original dataset as our train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8874c0-dd27-40c8-8fb4-363c612e7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_SI = sample(1:nrow(Ames_X_Data), size=ceiling(0.8*nrow(Ames_X_Data)))\n",
    "Test_SI = which(!(1:nrow(Ames_X_Data) %in% Train_SI))\n",
    "\n",
    "Ames_X_Train = Ames_X_Data[Train_SI,]\n",
    "Ames_X_Test = Ames_X_Data[Test_SI,]\n",
    "\n",
    "Ames_Y_Train = Ames_Y_Data[Train_SI]\n",
    "Ames_Y_Test = Ames_Y_Data[Test_SI]\n",
    "\n",
    "paste(\"Number of Observations in Training Set: \", nrow(Ames_X_Train), sep=\"\")\n",
    "paste(\"Number of Observations in Test Set: \", nrow(Ames_X_Test), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21adc15b-fd4a-4b8a-93e2-ce346a97c1e3",
   "metadata": {},
   "source": [
    "And at last, we make predictions using k-nearest neighbours (selecting k=9) on our test set using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d88bf5-0402-4ab1-8d76-03030f662409",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_Test_Preds = knn(Ames_X_Train, Ames_X_Test, Ames_Y_Train, k=9)\n",
    "table(KNN_Test_Preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c33fb78-7546-4f4a-83bc-265100c31a7f",
   "metadata": {},
   "source": [
    "### Part A\n",
    "\n",
    "Build the confusion matrix and then calculate the sensitivity, specificity, positive predictive value and negative predictive value by completing the following code (replace the `...` with appropriate code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c870c6b-e8bd-48c6-9b88-77c65feb5eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Confusion_Matrix = table(..., KNN_Test_Preds)\n",
    "\n",
    "Sensitivity = Con_Mat[1,1]/(Con_Mat[...,...]+Con_Mat[...,...])\n",
    "Specificity = Con_Mat[2,2]/(Con_Mat[...,...]+Con_Mat[...,...])\n",
    "\n",
    "PPV = Con_Mat[1,1]/(Con_Mat[...,...]+Con_Mat[...,...])\n",
    "NPV = Con_Mat[2,2]/(Con_Mat[...,...]+Con_Mat[...,...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd9b87a-86e7-4d4e-b2a2-f11ce988337a",
   "metadata": {},
   "source": [
    "(15 points) - 3 points for each correct line of code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b30dcb0-42a3-46b3-b63c-5462590bfb70",
   "metadata": {},
   "source": [
    "(5 bonus) - Use the appropriate functions in caret to compute these same measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfafd991-6cfa-4d01-b7ab-09bf13a538c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bonus\n",
    "\n",
    "library(caret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cc3bca-faf9-4056-a1c7-b2c498b82ff6",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "Explain in one or two sentences why using the \"accuracy\" measure for this problem is likely a bad idea.\n",
    "\n",
    "**Hint:** Examine the outcome more closely.\n",
    "\n",
    "(5 points) for correct reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262a8bef-6c88-4acb-91db-4c502417e55c",
   "metadata": {},
   "source": [
    "**[Answer Here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12df92b4-a25c-4c38-8337-7d6b7ce948c5",
   "metadata": {},
   "source": [
    "### Part C\n",
    "\n",
    "We can see the results from the confusion matrix that prediction of the \"N\" class using our k-nearest neighbours approach is very poor (only 5 out of 38 are correctly predicted), likely because the class is rare. Technically speaking, we can't perform any further modelling now that we've seen the test error (unless we have additional unused data leftover), because we otherwise risk overfitting (showing the importance of planning out your prediction modelling). \n",
    "\n",
    "However, for pedagogical purposes, let's assume we anticipated a problem with predicting this minority class in our data **before** we started modelling. Name a technique we could have used on the data to potentially improve predictive performance on the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c39d646-a65a-4f25-8362-2ab6f2ef35da",
   "metadata": {},
   "source": [
    "(5 points, 5 bonus) for correctly identifying one of the methods (and explaining what it does), another 5 bonus for explaining which is better to use for this specific problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833f4149-1740-4015-ab18-7cce44600e6c",
   "metadata": {},
   "source": [
    "**[Answer Here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76bd85-5685-404e-82cd-5f1a8305d842",
   "metadata": {},
   "source": [
    "### Part D\n",
    "\n",
    "Here is the code for the application of this technique from Part C, as well as running k-nearest neighbours (k=9) once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d55055-7dac-482d-a55f-cbcf757973e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Count = table(Ames_Y_Train)[1]\n",
    "N_Count = table(Ames_Y_Train)[2]\n",
    "Diff = Y_Count-N_Count\n",
    "N_Inds = which(Ames_Y_Train==\"N\")\n",
    "Repeats = sample(N_Inds, Diff, replace=TRUE)\n",
    "\n",
    "Ames_X_Train_New = rbind(Ames_X_Train, Ames_X_Train[Repeats,])\n",
    "Ames_Y_Train_New = c(Ames_Y_Train, Ames_Y_Train[Repeats])\n",
    "\n",
    "KNN_Test_Preds = knn(Ames_X_Train_New, Ames_X_Test, Ames_Y_Train_New, k=9)\n",
    "table(KNN_Test_Preds)\n",
    "table(Ames_Y_Test, KNN_Test_Preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ce27f2-bae0-4cad-be9c-c739f0b85480",
   "metadata": {},
   "source": [
    "We can see that the model is better at predicting the minority class, but now prediction of the majority class suffers (124 \"Y\" observations being predicted as \"N\"). This highlights the problem with k-nearest neighbours handling imbalanced outcome data. \n",
    "\n",
    "The `knn` function from the `class` package in R only takes the k-nearest neighbours and assigns predictions based on majority vote (ties are broken **randomly**). So if 5 of the neighbours are \"N\" and 4 of the neighbours are \"Y\", then the prediction point will be classified as \"N\", regardless of how close the \"Y\" neighbours are. \n",
    "\n",
    "How can we use the distances of the k-nearest neighbours of any given prediction point to potentially improve predictions? This can be a general explanation, no need for mathematical equations/expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a2fb12-f90f-47bd-98da-d403a32186a6",
   "metadata": {},
   "source": [
    "(5 points) for correct explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acb2a9b-a95e-45ab-9885-8c9d20eab422",
   "metadata": {},
   "source": [
    "**[Answer Here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115637e8-72b0-4079-94cc-84bbc27be016",
   "metadata": {},
   "source": [
    "### Part E\n",
    "\n",
    "As you may have noticed, we have not conducted any hyperparameter tuning of the k hyperparameter, instead we've always set k=9 (an initial, hopefully reasonable choice). However, let's consider a modelling approach where we do incorporate hyperparameter tuning to select and test our final model. Specifically, let's say that we're going to perform 20-fold cross-validation on our training set, repeated 100 times, to ultimately select the hyperparameter k with the best performance (let's say average of sensitivity and specificity).\n",
    "\n",
    "What is one possible concern with this approach (with respect to **specifically** the outcome class variable), and how can this problem be addressed?\n",
    "\n",
    "**Hint:** What's going to happen to the outcome distribution of each fold? Will each fold always have \"N\" observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da624fcf-161d-4ec9-a336-c602079be978",
   "metadata": {},
   "source": [
    "(5 points) for correctly identifying the problem and how it can be addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2858d6e4-9dde-47b5-8db9-1b72bee4cdd2",
   "metadata": {},
   "source": [
    "**[Answer Here]**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085656aa-969a-46a0-a7dd-4fa3b56d4b30",
   "metadata": {},
   "source": [
    "## Upload your work from Assignment 3\n",
    "\n",
    "- Each student will upload the Jupiter Notebook on Canvas Course 2: https://canvas.ubc.ca/courses/155856\n",
    "\n",
    " `Assignment_3C2_[team #]_[student name].ipynb`\n",
    "\n",
    "EXAMPLE: `Assignment_3C2_Team1_Nikolas_Krstic.ipynb`\n",
    "\n",
    "- Please write at the title who was responsible for writing each paragraph. \n",
    "\n",
    "Upload the word document on Canvas Course 2 under:\n",
    "`Assignments -> Assignment 3` \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
